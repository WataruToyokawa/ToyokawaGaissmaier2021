###############################################################################################
##
## Exploration of individual reinforcement learning parameters that give risk aversion or risk seeking
## Using tasks with a risky choice whose premium is 1.5 
## (i.e. expected value is 1.5 times as high as safe option)
## Wataru Toyokawa
## 30 March. 2020
##
###############################################################################################

## Assumptions

## - Rescorla-Wagner rule with time-fixed alpha
## - Softmax choice with fixed inverse temperature (no annealing; i.e. beta = beta_0 + 0 * t/T)
## - Individual differences in the learning parameters (see Toyokawa et al. (2019) Nat. Hum. Behav.)
## - payoff is generated by a Gaussian probability distribution with standard deviation sigma

rm(list=ls(all=TRUE)) # cleaning the workspace

# Loading
library(readr)
library(tidyverse)
library(ggplot2)
library(cowplot)
library(ggjoy)
library(foreach)
library(MASS)
library(doParallel)
registerDoParallel(detectCores())

## Load Functions
source('~/Dropbox/wataru/papers/RiskySocialLearning/riskPrem1.5_Gaussian/functions.R')

## -- Global parameter setting --
alphaList = seq(0.01,0.96,0.05)
invTemperatureList = seq(0,8,0.4)
annealing = 0
groupSizeList = c(10)
repetition = 10 #1000
horizon = 100 # = number of trials
numOptions = 2

## -- transformed parameters
alphaRawList = mapply(convert_alpha_to_alphaRaw, alphaList)

## -- Individual variation
variationAlphaRaw = 0.01 #1.5
variationBeta = 0.01#0.7
variatonAnnealing = 0.01#1.5

# -- Setting a two-armed bandit task --
riskPremium = 1.5
mu_sure = 1
mu_risky = mu_sure * riskPremium
sigma_sure = 0.03
sigma_risky = 1
initialExpextation = 0

# -- Initial Settings --
indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff = list()
groupSize = groupSizeList[1]
theta = 1


# -- simulation --
s_time = Sys.time()
for (alpha in alphaList) {
	for (invTemperature in invTemperatureList) {
	#for (annealing in annealingList) {
		indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff[[paste("n=", groupSize)]][[paste("alpha=", alpha)]][[paste("invTemperature=", invTemperature)]] <- foreach(rep = 1:repetition, .combine=rbind) %dopar% {
			## Initial settings
			choices = matrix(nrow=groupSize, ncol=horizon)
			payoffs = matrix(nrow=groupSize, ncol=horizon)
			performance = matrix(nrow=groupSize, ncol=horizon)
			safeChoiceProb = matrix(nrow=groupSize, ncol=horizon)
			isThisBestOption = matrix(nrow=groupSize, ncol=horizon)
			optimalChoiceProb = matrix(nrow=groupSize, ncol=horizon)
			expectedPerformance = matrix(nrow=groupSize, ncol=horizon)
			Q = array(dim = c(numOptions, horizon, groupSize))
			choiceCounter = array(1, dim = c(numOptions, groupSize))
			netChoiceProb = array(dim = c(numOptions, horizon, groupSize))
			netChoiceProb[,1,] = 1/numOptions
			Q[,1,] = initialExpextation
			socialFrequency = matrix(nrow=numOptions, ncol=horizon)
			socialFrequency[,] = 1e-1
			## Setting individual parameters
			thisAlpha = ( alphaRawList[which(alphaList==alpha)] + variationAlphaRaw * rt(groupSize, df = 14, ncp = 0) ) %>% mapply(convert_alphaRaw_to_alpha, .)
			thisBeta = invTemperature + variationBeta  * rt(groupSize, df = 14, ncp = 0)
			thisBeta[which(thisBeta<0)] <- 0
			#thisAnnealing = annealing + variatonAnnealing * rt(groupSize, df = 14, ncp = 0)
			thisAnnealing = 0
			for(t in 1:horizon){
				# each individual chooses one option based on his/her choice probability
				choices[,t] = mapply(function(p1,p2){ sample(1:numOptions, 1, prob=c(p1,p2), replace=FALSE) }, netChoiceProb[1,t,], netChoiceProb[2,t,] )
				# each subject earns some money (if lucky)
				payoffs[,t] = payoffGenerateGaussian(groupSize, choices[,t], mu_sure, mu_risky, sigma_sure, sigma_risky)
				# update choiceCounter and learningRate (if the learning rate is an averaging rule in this simulation.)
				updatingPositions = (choices[,t] + numOptions*(1:groupSize-1))
				# -- (if the learning rate is an averaging rule in this simulation.) --
				#choiceCounter = aperm(choiceCounter, c(2,1)) # transform the choiceCounter matrix
				#dim(choiceCounter) = c(numOptions*groupSize) # reduce dimension
				#choiceCounter[updatingPositions] = choiceCounter[updatingPositions] + 1
				#learningRate = 1/choiceCounter # Learning rate is now set
				#dim(choiceCounter) = c(numOptions, groupSize)
				# -- END --
				if(t < horizon) {
					if(t == 1) {
						Q[,t+1,] = Q[,t,]
						QQ = aperm(Q, c(1,3,2))
						dim(QQ) = c(numOptions*groupSize, horizon)
						# In the first trial, all Q values are updated by the first experience
						QQ[,t+1] = QQ[,t] + thisAlpha * (payoffs[,t] - QQ[,t])
						dim(QQ) = c(numOptions, groupSize, horizon)
						Q = aperm(QQ, c(1,3,2))
					} else {
						# Updating Q value based on Rescorla-Wagner model (Weighted return model)
						Q[,t+1,] = Q[,t,]
						QQ = aperm(Q, c(1,3,2))
						dim(QQ) = c(numOptions*groupSize, horizon)
						#QQ[updatingPositions,t+1] = QQ[updatingPositions,t] + learningRate[updatingPositions] * (payoffs[,t] - QQ[updatingPositions,t])
						QQ[updatingPositions,t+1] = QQ[updatingPositions,t] + thisAlpha * (payoffs[,t] - QQ[updatingPositions,t])
						dim(QQ) = c(numOptions, groupSize, horizon)
						Q = aperm(QQ, c(1,3,2))
					}
					# update socialFrequency
					## Option 1's frequency
					#if(length(which(names(table(choices[,t]))==1))>0) {
					#	socialFrequency[1,t+1] = socialFrequency[1,t+1] + table(choices[,t])[which(names(table(choices[,t]))==1)][1]
					#}
					## Option 2's frequency
					#if(length(which(names(table(choices[,t]))==2))>0) {
					#	socialFrequency[2,t+1] = socialFrequency[2,t+1] + table(choices[,t])[which(names(table(choices[,t]))==2)][1]
					#}
					# Calculating the next choice probability
					# It depends on what strategy each agent deploys
					# In the original article, March only considered a proportional choice
					# If you want to implement softmax rule, you should modify this
					#proportionalChoiceMatrix = Q[,t+1,] %>% apply(1, divideVector, denominator = apply(Q[,t+1,],2,sum)) %>% t()

					###############
					## Softmax choice base solely on Q values
					###############
					#Q_exp = apply(Q[,t+1,], 1, multiplyBeta, beta = (thisBeta + thisAnnealing * (t+1)/horizon) ) %>% t() %>% apply(2,expCeiling)
					Q_exp = ( Q[,t+1,] * rep((thisBeta + thisAnnealing * (t+1)/horizon), each = numOptions) ) %>% apply(2,expCeiling)
					softmaxMatrix = Q_exp %>% apply(1, divideVector, denominator = apply(Q_exp,2,sum)) %>% t()
					#freqDepenMatrix = frequencyDependentCopy(socialFrequency[,t+1], choices[,t], theta, numOptions)
					## The followings update the choice probability matrix
					###############
					## Softmax -- END
					###############

					#soc = 1/(1+exp(-(soc_raw)))
					soc = 0 # soc = 0 indicates asocial learning (i.e. no social info use)
					##netMatrix = apply(softmaxMatrix, 1, multiplyBeta, beta=(1-epsilon*numOptions)) %>% t() + epsilon
					#netMatrix = apply(softmaxMatrix, 1, multiplyBeta, beta=(1-soc)) %>% t() + apply(freqDepenMatrix, 1, multiplyBeta, beta=soc) %>% t()
					netMatrix = softmaxMatrix #apply(softmaxMatrix, 1, multiplyBeta, beta=1) %>% t()
					netChoiceProbAperm = aperm(netChoiceProb, c(1,3,2))
					dim(netChoiceProbAperm) = c(numOptions*groupSize, horizon)
					dim(netMatrix) = c(numOptions*groupSize, 1)
					netChoiceProbAperm[,t+1] = netMatrix
					dim(netChoiceProbAperm) = c(numOptions, groupSize, horizon)
					netChoiceProb = aperm(netChoiceProbAperm, c(1,3,2))
				}
			}

			for(i in 1:groupSize) {
				safeChoiceProb[i,] = netChoiceProb[1,,i]
			}

			safeChoiceProbMean = safeChoiceProb %>% mean()

			# Submitting this repetition's result
			print(
				c(
					groupSize,
					alpha,
					invTemperature,
					safeChoiceProbMean
				)
			)
		}
		gc();gc() # rubbish collection
	}
}
e_time = Sys.time()
e_time - s_time
# -- simulation END --

# -- saving the data --
indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data = indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff[[paste("n=",groupSizeList[1])]][[paste("alpha=",alphaList[1])]][[paste("invTemperature=",invTemperatureList[1])]] %>% data.frame()

for (groupSize in groupSizeList) {
	for (alpha in alphaList) {
		for (invTemperature in invTemperatureList) {
			if(groupSize!=groupSizeList[1] | alpha!=alphaList[1] | invTemperature!=invTemperatureList[1]) {
				indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data = indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data %>% rbind(data.frame(indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff[[paste("n=",groupSize)]][[paste("alpha=",alpha)]][[paste("invTemperature=",invTemperature)]]))
			}
		}
	}
}

names(indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data) = c('groupSize', 'learningRate', 'invTemperature', 'proportionSafeChoice')


indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_summary <- indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data %>%
	group_by(groupSize, learningRate, invTemperature) %>%
	summarise(
		mean_proportionSafeChoice = mean(proportionSafeChoice, na.rm = TRUE),
	    median_proportionSafeChoice = median(proportionSafeChoice, na.rm = TRUE),
	    sd_proportionSafeChoice = sd(proportionSafeChoice, na.rm = TRUE)
		)

indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_summary %>%
	ggplot() +
	geom_raster(mapping = aes(learningRate, invTemperature, fill = mean_proportionSafeChoice), stat = 'identity') +
	labs(x=expression(paste('Learning rate ',bar(alpha),sep="")), y=expression(paste('Inverse temperature ',bar(beta),sep="")), title='ResWag + Softmax\n Risk Premium 1.5 (sigma=0.7)', fill = "Proportion of\nsafe choice")+
	#scale_fill_viridis(limits = c(0.45, 1), option="magma")+
	scale_fill_gradient2(midpoint = 0.5, low = "red", mid = "grey90", high = "blue")+
	#myTheme_gillsansMT()+
	myTheme_gillsans()+
	NULL -> indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_mean
indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_mean


indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_summary %>%
	ggplot() +
	geom_raster(mapping = aes(learningRate, invTemperature, fill = sd_proportionSafeChoice), stat = 'identity') +
	labs(x=expression(paste('Learning rate ',bar(alpha),sep="")), y=expression(paste('Inverse temperature ',bar(beta),sep="")), title='ResWag + Softmax\n Risk Premium 1.5 (sigma=0.7)', fill="SD of\nsafe choice rate")+
	scale_fill_viridis_c(option="magma")+
	#scale_fill_gradient2(midpoint = 0.5, low = "red", mid = "grey90", high = "blue")+
	#myTheme_gillsansMT()+
	myTheme_gillsans()+
	NULL -> indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_sd
indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_sd

ggsave(file = "~/Dropbox/wataru/papers/RiskySocialLearning/riskPrem1.5_Gaussian/results/indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_mean.png", plot = indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_mean, dpi = 300, width = 6, height = 4.5)
ggsave(file = "~/Dropbox/wataru/papers/RiskySocialLearning/riskPrem1.5_Gaussian/results/indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_sd.png", plot = indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_plot_sd, dpi = 300, width = 6, height = 4.5)


write.csv(indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data,
			"~/Dropbox/wataru/papers/RiskySocialLearning/riskPrem1.5_Gaussian/results/indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data.csv",
			row.names=FALSE)

indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data <- read_csv("~/Dropbox/wataru/papers/RiskySocialLearning/riskPrem1.5_Gaussian/results/indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data.csv")
indivParamSearch_indiv_riskPrem150_Gaussian_indivDiff_data$learningRate = rep(alphaList, each = length(invTemperatureList)*repetition) %>% rep(length(groupSizeList))

